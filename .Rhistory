summarise(cor(runs, at_bats))
m1 <- lm(runs ~ at_bats, data = mlb11)
summary(m1)
m2 <- lm(runs ~ homeruns, data = mlb11)
summary(m2)
ggplot(data = mlb11, aes(x = at_bats, y = runs)) +
geom_point() +
stat_smooth(method = "lm", se = FALSE)
pred_5579 <- predict(m1, newdata = data.frame(at_bats = 5579))
obs_5579 <- mlb11 %>% filter(at_bats == 5579) %>% pull(runs)
residual_5579 <- obs_5579 - pred_5579
residual_5579
ggplot(data = m1, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed") +
xlab("Fitted values") +
ylab("Residuals")
ggplot(data = m1, aes(x = .resid)) +
geom_histogram(binwidth = 25) +
xlab("Residuals")
ggplot(data = m1, aes(sample = .resid)) +
stat_qq()
## Elegí "hits" como predictor alternativo y muestro gráfico y modelo
ggplot(data = mlb11, aes(x = hits, y = runs)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "Hits", y = "Runs", title = "Runs vs Hits")
m_hits <- lm(runs ~ hits, data = mlb11)
summary(m_hits)
r2_atbats <- summary(m1)$r.squared
r2_hits <- summary(m_hits)$r.squared
data.frame(variable = c("at_bats", "hits"), r_squared = c(r2_atbats, r2_hits))
vars <- c("at_bats", "hits", "homeruns", "batting_avg", "strikeouts", "stolen_bases", "wins")
r2s <- sapply(vars, function(v){
f <- as.formula(paste("runs ~", v))
summary(lm(f, data = mlb11))$r.squared
})
library(statsr)
library(dplyr)
library(ggplot2)
data(mlb11)
ggplot(data = mlb11, aes(x = at_bats, y = runs)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "At bats", y = "Runs", title = "Runs vs At bats")
mlb11 %>%
summarise(cor(runs, at_bats))
m1 <- lm(runs ~ at_bats, data = mlb11)
summary(m1)
m2 <- lm(runs ~ homeruns, data = mlb11)
summary(m2)
ggplot(data = mlb11, aes(x = at_bats, y = runs)) +
geom_point() +
stat_smooth(method = "lm", se = FALSE)
pred_5579 <- predict(m1, newdata = data.frame(at_bats = 5579))
obs_5579 <- mlb11 %>% filter(at_bats == 5579) %>% pull(runs)
residual_5579 <- obs_5579 - pred_5579
residual_5579
ggplot(data = m1, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed") +
xlab("Fitted values") +
ylab("Residuals")
ggplot(data = m1, aes(x = .resid)) +
geom_histogram(binwidth = 25) +
xlab("Residuals")
ggplot(data = m1, aes(sample = .resid)) +
stat_qq()
## Elegí "hits" como predictor alternativo y muestro gráfico y modelo
ggplot(data = mlb11, aes(x = hits, y = runs)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "Hits", y = "Runs", title = "Runs vs Hits")
m_hits <- lm(runs ~ hits, data = mlb11)
summary(m_hits)
r2_atbats <- summary(m1)$r.squared
r2_hits <- summary(m_hits)$r.squared
data.frame(variable = c("at_bats", "hits"), r_squared = c(r2_atbats, r2_hits))
vars <- c("at_bats", "hits", "homeruns", "batting_avg", "strikeouts", "stolen_bases", "wins")
r2s <- sapply(vars, function(v){
f <- as.formula(paste("runs ~", v))
summary(lm(f, data = mlb11))$r.squared
})
library(statsr)
library(dplyr)
library(ggplot2)
data(mlb11)
ggplot(data = mlb11, aes(x = at_bats, y = runs)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "At bats", y = "Runs", title = "Runs vs At bats")
mlb11 %>%
summarise(cor(runs, at_bats))
m1 <- lm(runs ~ at_bats, data = mlb11)
summary(m1)
m2 <- lm(runs ~ homeruns, data = mlb11)
summary(m2)
ggplot(data = mlb11, aes(x = at_bats, y = runs)) +
geom_point() +
stat_smooth(method = "lm", se = FALSE)
pred_5579 <- predict(m1, newdata = data.frame(at_bats = 5579))
obs_5579 <- mlb11 %>% filter(at_bats == 5579) %>% pull(runs)
residual_5579 <- obs_5579 - pred_5579
residual_5579
ggplot(data = m1, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed") +
xlab("Fitted values") +
ylab("Residuals")
ggplot(data = m1, aes(x = .resid)) +
geom_histogram(binwidth = 25) +
xlab("Residuals")
ggplot(data = m1, aes(sample = .resid)) +
stat_qq()
## Elegí "hits" como predictor alternativo y muestro gráfico y modelo
ggplot(data = mlb11, aes(x = hits, y = runs)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "Hits", y = "Runs", title = "Runs vs Hits")
m_hits <- lm(runs ~ hits, data = mlb11)
summary(m_hits)
r2_atbats <- summary(m1)$r.squared
r2_hits <- summary(m_hits)$r.squared
data.frame(variable = c("at_bats", "hits"), r_squared = c(r2_atbats, r2_hits))
# Detectar variables disponibles en el dataset para evitar errores por nombres inexistentes
candidate_vars <- c(
"at_bats", "hits", "homeruns",
# posibles nombres para batting average
"batting_avg", "batting.avg", "avg", "battingAverage",
"strikeouts", "stolen_bases", "wins"
)
vars <- intersect(candidate_vars, names(mlb11))
if(!"at_bats" %in% names(mlb11)) message("Nota: 'at_bats' no está presente en el dataset; usando las variables encontradas: ", paste(vars, collapse=", "))
if(length(vars) == 0) stop("No se encontraron variables predictoras candidatas en 'mlb11'. Revisa los nombres de columnas.")
r2s <- sapply(vars, function(v){
f <- as.formula(paste("runs ~", v))
summary(lm(f, data = mlb11))$r.squared
})
r2_tbl <- data.frame(variable = vars, r_squared = as.numeric(r2s), row.names = NULL)
r2_tbl <- r2_tbl[order(-r2_tbl$r_squared), ]
r2_tbl
# Buscar nombres relacionados con on-base y slugging en el dataset (distintas convenciones posibles)
pattern_new <- "on.?base|slug|ops|on_base|onbase|onbaseplus|onbase_plus|onbaseplusslug|obs"
new_vars_found <- names(mlb11)[grepl(pattern_new, names(mlb11), ignore.case = TRUE)]
if(length(new_vars_found) == 0){
# fallback a nombres comunes usados en el lab
fallback <- c("new_obs", "new_slug", "new_onbase")
new_vars <- intersect(fallback, names(mlb11))
} else {
new_vars <- new_vars_found
}
if(length(new_vars) == 0){
message("No se encontraron variables 'nuevas' relacionadas con on-base/slugging en 'mlb11'.")
data.frame(variable = character(0), r_squared = numeric(0))
} else {
r2_new <- sapply(new_vars, function(v){
f <- as.formula(paste("runs ~", v))
summary(lm(f, data = mlb11))$r.squared
})
data.frame(variable = new_vars, r_squared = as.numeric(r2_new))[order(-r2_new), ]
}
## Selecciono el mejor predictor según r2_tbl calculado antes (preg. 9)
best_var <- r2_tbl$variable[1]
best_model <- lm(as.formula(paste("runs ~", best_var)), data = mlb11)
summary(best_model)
## Gráficos de diagnóstico (usa la salida gráfica base de R)
par(mfrow = c(2,2))
plot(best_model)
par(mfrow = c(1,1))
library(statsr)
library(dplyr)
library(ggplot2)
library(GGally)
data(evals)
summary(evals$score)
ggplot(evals, aes(x = score)) +
geom_histogram(binwidth = 0.2, color = "black", fill = "skyblue") +
xlab("Score") + ylab("Count") + ggtitle("Distribución de score")
## Ejemplo 1: relación numérica-numérica
ggplot(evals, aes(x = cls_students, y = cls_perc_eval)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "Número de estudiantes", y = "% completaron evaluación", title = "cls_students vs cls_perc_eval")
## Ejemplo 2: categórica vs numérica
ggplot(evals, aes(x = rank, y = score)) +
geom_boxplot() +
labs(title = "Distribución de score por rank")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_point()
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter(width = 0.1, height = 0.05, alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Score vs bty_avg (jitter)")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter() +
geom_smooth(method = "lm")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter() +
geom_smooth(method = "lm", se = FALSE)
m_bty <- lm(score ~ bty_avg, data = evals)
summary(m_bty)
# Coeficientes (ecuación)
coef(m_bty)
par(mfrow = c(2,2))
plot(m_bty)
par(mfrow = c(1,1))
## Resumen de residuales
summary(residuals(m_bty))
ggplot(data = evals, aes(x = bty_f1lower, y = bty_avg)) +
geom_jitter()
evals %>%
summarise(cor(bty_avg, bty_f1lower))
ggpairs(evals, columns = 13:19)
m_bty_gen <- lm(score ~ bty_avg + gender, data = evals)
summary(m_bty_gen)
par(mfrow = c(2,2))
plot(m_bty_gen)
par(mfrow = c(1,1))
summary(residuals(m_bty_gen))
summary(m_bty_gen)
## Comparar coeficiente de bty_avg entre modelos
data.frame(model = c("simple", "with_gender"), bty_coef = c(coef(m_bty)["bty_avg"], coef(m_bty_gen)["bty_avg"]))
m_bty_rank <- lm(score ~ bty_avg + rank, data = evals)
summary(m_bty_rank)
## Mostrar cómo R codifica las variables categóricas
contrasts(evals$rank)
newprof <- data.frame(gender = "male", bty_avg = 3)
predict(m_bty_gen, newprof)
predict(m_bty_gen, newprof, interval = "prediction", level = 0.95)
m_full <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg
+ pic_outfit + pic_color, data = evals)
summary(m_full)
# type your code for the Exercise here, and Knit
# type your code for the Exercise here, and Knit
library(statsr)
library(dplyr)
library(ggplot2)
library(GGally)
data(evals)
summary(evals$score)
ggplot(evals, aes(x = score)) +
geom_histogram(binwidth = 0.2, color = "black", fill = "skyblue") +
xlab("Score") + ylab("Count") + ggtitle("Distribución de score")
## Ejemplo 1: relación numérica-numérica
ggplot(evals, aes(x = cls_students, y = cls_perc_eval)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "Número de estudiantes", y = "% completaron evaluación", title = "cls_students vs cls_perc_eval")
## Ejemplo 2: categórica vs numérica
ggplot(evals, aes(x = rank, y = score)) +
geom_boxplot() +
labs(title = "Distribución de score por rank")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_point()
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter(width = 0.1, height = 0.05, alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Score vs bty_avg (jitter)")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter() +
geom_smooth(method = "lm")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter() +
geom_smooth(method = "lm", se = FALSE)
m_bty <- lm(score ~ bty_avg, data = evals)
summary(m_bty)
# Coeficientes (ecuación)
coef(m_bty)
par(mfrow = c(2,2))
plot(m_bty)
par(mfrow = c(1,1))
## Resumen de residuales
summary(residuals(m_bty))
ggplot(data = evals, aes(x = bty_f1lower, y = bty_avg)) +
geom_jitter()
evals %>%
summarise(cor(bty_avg, bty_f1lower))
ggpairs(evals, columns = 13:19)
m_bty_gen <- lm(score ~ bty_avg + gender, data = evals)
summary(m_bty_gen)
par(mfrow = c(2,2))
plot(m_bty_gen)
par(mfrow = c(1,1))
summary(residuals(m_bty_gen))
summary(m_bty_gen)
## Comparar coeficiente de bty_avg entre modelos
data.frame(model = c("simple", "with_gender"), bty_coef = c(coef(m_bty)["bty_avg"], coef(m_bty_gen)["bty_avg"]))
m_bty_rank <- lm(score ~ bty_avg + rank, data = evals)
summary(m_bty_rank)
## Mostrar cómo R codifica las variables categóricas
contrasts(evals$rank)
newprof <- data.frame(gender = "male", bty_avg = 3)
predict(m_bty_gen, newprof)
predict(m_bty_gen, newprof, interval = "prediction", level = 0.95)
m_full <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg
+ pic_outfit + pic_color, data = evals)
summary(m_full)
## Identificar término con mayor p-valor (considerando todas las filas asociadas al término)
coef_tbl <- summary(m_full)$coefficients
term_labels <- attr(terms(m_full), "term.labels")
term_pvals <- sapply(term_labels, function(t){
# filas cuyos nombres comienzan por el término (maneja factores con múltiples niveles)
rows <- grepl(paste0('^', t), rownames(coef_tbl))
if(!any(rows)) return(NA)
max(coef_tbl[rows, 4], na.rm = TRUE)
})
term_pvals_df <- data.frame(term = term_labels, max_p = term_pvals, row.names = NULL)
term_pvals_df[order(-term_pvals_df$max_p), ]
# Término con mayor p-valor
drop_term <- term_pvals_df$term[which.max(term_pvals_df$max_p)]
cat("Dropping term with largest p-value:", drop_term, "(p=", round(max(term_pvals_df$max_p), 4), ")\n")
# Reajustar modelo sin ese término
m_reduced <- update(m_full, paste0(". ~ . - ", drop_term))
summary(m_reduced)
# Comparar coeficientes entre modelos
coefs_full <- coef(summary(m_full))
coefs_red <- coef(summary(m_reduced))
all_coef_names <- union(rownames(coefs_full), rownames(coefs_red))
comp <- data.frame(
term = all_coef_names,
estimate_full = ifelse(all_coef_names %in% rownames(coefs_full), coefs_full[all_coef_names,1], NA),
p_full = ifelse(all_coef_names %in% rownames(coefs_full), coefs_full[all_coef_names,4], NA),
estimate_reduced = ifelse(all_coef_names %in% rownames(coefs_red), coefs_red[all_coef_names,1], NA),
p_reduced = ifelse(all_coef_names %in% rownames(coefs_red), coefs_red[all_coef_names,4], NA)
)
library(statsr)
library(dplyr)
library(ggplot2)
library(GGally)
data(evals)
summary(evals$score)
ggplot(evals, aes(x = score)) +
geom_histogram(binwidth = 0.2, color = "black", fill = "skyblue") +
xlab("Score") + ylab("Count") + ggtitle("Distribución de score")
## Ejemplo 1: relación numérica-numérica
ggplot(evals, aes(x = cls_students, y = cls_perc_eval)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "Número de estudiantes", y = "% completaron evaluación", title = "cls_students vs cls_perc_eval")
## Ejemplo 2: categórica vs numérica
ggplot(evals, aes(x = rank, y = score)) +
geom_boxplot() +
labs(title = "Distribución de score por rank")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_point()
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter(width = 0.1, height = 0.05, alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Score vs bty_avg (jitter)")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter() +
geom_smooth(method = "lm")
ggplot(data = evals, aes(x = bty_avg, y = score)) +
geom_jitter() +
geom_smooth(method = "lm", se = FALSE)
m_bty <- lm(score ~ bty_avg, data = evals)
summary(m_bty)
# Coeficientes (ecuación)
coef(m_bty)
par(mfrow = c(2,2))
plot(m_bty)
par(mfrow = c(1,1))
## Resumen de residuales
summary(residuals(m_bty))
ggplot(data = evals, aes(x = bty_f1lower, y = bty_avg)) +
geom_jitter()
evals %>%
summarise(cor(bty_avg, bty_f1lower))
ggpairs(evals, columns = 13:19)
m_bty_gen <- lm(score ~ bty_avg + gender, data = evals)
summary(m_bty_gen)
par(mfrow = c(2,2))
plot(m_bty_gen)
par(mfrow = c(1,1))
summary(residuals(m_bty_gen))
summary(m_bty_gen)
## Comparar coeficiente de bty_avg entre modelos
data.frame(model = c("simple", "with_gender"), bty_coef = c(coef(m_bty)["bty_avg"], coef(m_bty_gen)["bty_avg"]))
m_bty_rank <- lm(score ~ bty_avg + rank, data = evals)
summary(m_bty_rank)
## Mostrar cómo R codifica las variables categóricas
contrasts(evals$rank)
newprof <- data.frame(gender = "male", bty_avg = 3)
predict(m_bty_gen, newprof)
predict(m_bty_gen, newprof, interval = "prediction", level = 0.95)
m_full <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg
+ pic_outfit + pic_color, data = evals)
summary(m_full)
## Identificar término con mayor p-valor (considerando todas las filas asociadas al término)
coef_tbl <- summary(m_full)$coefficients
term_labels <- attr(terms(m_full), "term.labels")
term_pvals <- sapply(term_labels, function(t){
# filas cuyos nombres comienzan por el término (maneja factores con múltiples niveles)
rows <- grepl(paste0('^', t), rownames(coef_tbl))
if(!any(rows)) return(NA)
max(coef_tbl[rows, 4], na.rm = TRUE)
})
term_pvals_df <- data.frame(term = term_labels, max_p = term_pvals, row.names = NULL)
term_pvals_df[order(-term_pvals_df$max_p), ]
# Término con mayor p-valor
drop_term <- term_pvals_df$term[which.max(term_pvals_df$max_p)]
cat("Dropping term with largest p-value:", drop_term, "(p=", round(max(term_pvals_df$max_p), 4), ")\n")
# Reajustar modelo sin ese término
m_reduced <- update(m_full, paste0(". ~ . - ", drop_term))
summary(m_reduced)
# Comparar coeficientes entre modelos (forma segura)
coefs_full <- coef(summary(m_full))
coefs_red <- coef(summary(m_reduced))
all_coef_names <- union(rownames(coefs_full), rownames(coefs_red))
estimate_full <- rep(NA, length(all_coef_names))
p_full <- rep(NA, length(all_coef_names))
estimate_reduced <- rep(NA, length(all_coef_names))
p_reduced <- rep(NA, length(all_coef_names))
idx_full <- match(all_coef_names, rownames(coefs_full))
idx_red <- match(all_coef_names, rownames(coefs_red))
has_full <- !is.na(idx_full)
has_red <- !is.na(idx_red)
if(any(has_full)){
estimate_full[has_full] <- coefs_full[idx_full[has_full], 1]
p_full[has_full] <- coefs_full[idx_full[has_full], 4]
}
if(any(has_red)){
estimate_reduced[has_red] <- coefs_red[idx_red[has_red], 1]
p_reduced[has_red] <- coefs_red[idx_red[has_red], 4]
}
comp <- data.frame(
term = all_coef_names,
estimate_full = estimate_full,
p_full = p_full,
estimate_reduced = estimate_reduced,
p_reduced = p_reduced,
row.names = NULL,
stringsAsFactors = FALSE
)
head(comp, n = 20)
## Probar eliminar cada término de m_full y comparar adjusted R^2
terms_all <- attr(terms(m_full), "term.labels")
adj_changes <- sapply(terms_all, function(t){
m_try <- update(m_full, paste0('. ~ . - ', t))
summary(m_try)$adj.r.squared - summary(m_full)$adj.r.squared
})
adj_df <- data.frame(term = terms_all, adj_r_change = as.numeric(adj_changes), row.names = NULL)
adj_df <- adj_df[order(-adj_df$adj_r_change), ]
adj_df
cat('\nMejor remoción (mayor incremento en adjusted R^2):\n')
print(head(adj_df,1))
source("C:/Users/mikia/Downloads/Taller R/Taller bayesiano.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Montecarlo_simulation.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Montecarlo_simulation.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Montecarlo_simulation.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Muestreador Gibbs.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Muestreador Gibbs.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Muestreador Gibbs.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/mosdelo lineal bayesiano.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/modelo de regresion lineal.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/modelo de regresion lineal.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/ancome.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/ancome.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/ancome.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/DICMontecarlo.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/DIC2.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/poisson1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/poisson1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/poisson_callers.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/poisson_callers.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/verificacion de coeficiente.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/verificacion de coeficiente.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/distribucion mu.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/distribucion mu.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/modelo jerarquco.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/modelo jerarquico 2.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/DIC Jerarquico.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
