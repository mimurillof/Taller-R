coefs_red <- coef(summary(m_reduced))
all_coef_names <- union(rownames(coefs_full), rownames(coefs_red))
estimate_full <- rep(NA, length(all_coef_names))
p_full <- rep(NA, length(all_coef_names))
estimate_reduced <- rep(NA, length(all_coef_names))
p_reduced <- rep(NA, length(all_coef_names))
idx_full <- match(all_coef_names, rownames(coefs_full))
idx_red <- match(all_coef_names, rownames(coefs_red))
has_full <- !is.na(idx_full)
has_red <- !is.na(idx_red)
if(any(has_full)){
estimate_full[has_full] <- coefs_full[idx_full[has_full], 1]
p_full[has_full] <- coefs_full[idx_full[has_full], 4]
}
if(any(has_red)){
estimate_reduced[has_red] <- coefs_red[idx_red[has_red], 1]
p_reduced[has_red] <- coefs_red[idx_red[has_red], 4]
}
comp <- data.frame(
term = all_coef_names,
estimate_full = estimate_full,
p_full = p_full,
estimate_reduced = estimate_reduced,
p_reduced = p_reduced,
row.names = NULL,
stringsAsFactors = FALSE
)
head(comp, n = 20)
## Probar eliminar cada término de m_full y comparar adjusted R^2
terms_all <- attr(terms(m_full), "term.labels")
adj_changes <- sapply(terms_all, function(t){
m_try <- update(m_full, paste0('. ~ . - ', t))
summary(m_try)$adj.r.squared - summary(m_full)$adj.r.squared
})
adj_df <- data.frame(term = terms_all, adj_r_change = as.numeric(adj_changes), row.names = NULL)
adj_df <- adj_df[order(-adj_df$adj_r_change), ]
adj_df
cat('\nMejor remoción (mayor incremento en adjusted R^2):\n')
print(head(adj_df,1))
source("C:/Users/mikia/Downloads/Taller R/Taller bayesiano.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Montecarlo_simulation.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Montecarlo_simulation.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Montecarlo_simulation.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Muestreador Gibbs.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Muestreador Gibbs.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Muestreador Gibbs.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/mosdelo lineal bayesiano.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/modelo de regresion lineal.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/modelo de regresion lineal.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/ancome.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/ancome.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/ancome.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/DICMontecarlo.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/DIC2.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/HDP.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/MASS.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/poisson1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/poisson1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/poisson_callers.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/poisson_callers.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/verificacion de coeficiente.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/verificacion de coeficiente.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/distribucion mu.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/distribucion mu.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/modelo jerarquco.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/modelo jerarquico 2.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/DIC Jerarquico.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/calls_misture.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
source("C:/Users/mikia/Downloads/Taller R/Proyecto_1.R", echo = TRUE)
knitr::opts_chunk$set(
echo = TRUE,
warning = FALSE,
message = FALSE,
fig.align = "center",
cache = FALSE
)
# Cargar librerías necesarias
library(quantmod)
library(ggplot2)
library(tidyr)
library(dplyr)
library(rjags)
library(coda)
library(knitr)
library(DT)
# Definir parámetros
initial_tickers <- c("SPY", "XLK", "XLF", "XLP", "XLE")
start_date <- "2018-01-01"
end_date <- "2024-12-31"
# Descargar datos en entorno aislado
data_env <- new.env()
getSymbols(initial_tickers,
env = data_env,
from = start_date,
to = end_date,
src = "yahoo")
# Verificar descarga exitosa
successful_tickers <- ls(data_env)
cat("Tickers descargados exitosamente:", paste(successful_tickers, collapse = ", "))
if (length(successful_tickers) < length(initial_tickers)) {
missing_tickers <- setdiff(initial_tickers, successful_tickers)
warning(paste("Tickers faltantes:", paste(missing_tickers, collapse = ", ")))
}
# Extraer precios ajustados
adjusted_prices <- lapply(successful_tickers, function(ticker) {
Ad(data_env[[ticker]])
})
# Combinar series de precios
merged_prices <- do.call(merge, adjusted_prices)
colnames(merged_prices) <- successful_tickers
# Calcular retornos logarítmicos
log_returns_list <- lapply(1:ncol(merged_prices), function(i) {
dailyReturn(merged_prices[, i], type = 'log')
})
log_returns <- do.call(merge, log_returns_list)
colnames(log_returns) <- successful_tickers
clean_log_returns <- na.omit(log_returns)
# Convertir a data frame para análisis
returns_df <- as.data.frame(clean_log_returns)
# Mostrar estadísticas descriptivas
cat("Observaciones totales:", nrow(returns_df))
cat("\nRango de fechas:", rownames(returns_df)[1], "a", rownames(returns_df)[nrow(returns_df)])
# Estadísticas descriptivas
desc_stats <- returns_df %>%
summarise_all(list(
Media = ~mean(., na.rm = TRUE),
`Desv.Est` = ~sd(., na.rm = TRUE),
`Volatilidad Anual` = ~sd(., na.rm = TRUE) * sqrt(252)
)) %>%
tidyr::gather(key = "Stat_Ticker", value = "Value") %>%
tidyr::separate(Stat_Ticker, into = c("Ticker", "Statistic"), sep = "_") %>%
tidyr::spread(Statistic, Value) %>%
mutate(across(where(is.numeric), ~round(., 4)))
kable(desc_stats, caption = "Estadísticas Descriptivas de Retornos Diarios",
format = "html", table.attr = "class='table table-striped'")
# Preparar datos para análisis exploratorio
if ("SPY" %in% colnames(returns_df)) {
returns_long <- returns_df %>%
pivot_longer(cols = -SPY,
names_to = "Sector",
values_to = "Sector_Return")
# Crear mapeo de sectores a nombres descriptivos
sector_labels <- c(
"XLE" = "Energía",
"XLF" = "Finanzas",
"XLK" = "Tecnología",
"XLP" = "Consumo Básico"
)
returns_long <- returns_long %>%
mutate(Sector_Label = factor(sector_labels[Sector],
levels = c("Energía", "Finanzas", "Tecnología", "Consumo Básico")))
# Gráfico principal de relaciones
exploratory_plot <- ggplot(returns_long, aes(x = SPY, y = Sector_Return)) +
geom_point(alpha = 0.3, color = "steelblue", size = 0.8) +
geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1) +
facet_wrap(~ Sector_Label, ncol = 2, scales = "free") +
labs(
title = "Relación de Retornos Sectoriales vs. Mercado (S&P 500)",
subtitle = "Datos diarios: Enero 2018 - Diciembre 2024",
x = "Retornos del Mercado (SPY)",
y = "Retornos del Sector",
caption = "Fuente: Yahoo Finance. Análisis propio."
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12),
strip.text = element_text(size = 11, face = "bold")
) +
geom_hline(yintercept = 0, linetype = "dashed", color = "gray50", alpha = 0.7) +
geom_vline(xintercept = 0, linetype = "dashed", color = "gray50", alpha = 0.7)
print(exploratory_plot)
}
# Crear índice numérico para sectores
returns_long <- returns_long %>%
mutate(Sector_Index = as.numeric(as.factor(Sector)))
# Lista de datos para JAGS
jags_data <- list(
R_sector = returns_long$Sector_Return,
R_market = returns_long$SPY,
sector_idx = returns_long$Sector_Index,
N = nrow(returns_long),
J = length(unique(returns_long$Sector))
)
# Guardar nombres de sectores
sector_names <- levels(as.factor(returns_long$Sector))
cat("Sectores incluidos:", paste(sector_names, collapse = ", "))
cat("\nObservaciones totales:", jags_data$N)
cat("\nNúmero de sectores:", jags_data$J)
# Modelo jerárquico en JAGS
model_string <- "
model {
# --- 1. Verosimilitud (Likelihood) ---
for (i in 1:N) {
R_sector[i] ~ dnorm(mu[i], tau[sector_idx[i]])
mu[i] <- alpha[sector_idx[i]] + beta[sector_idx[i]] * R_market[i]
}
# --- 2. Priors de Nivel de Sector ---
for (j in 1:J) {
# Estructura jerárquica para Beta y Alfa
beta[j] ~ dnorm(mu_beta, tau_beta)
alpha[j] ~ dnorm(mu_alpha, tau_alpha)
# Prior para la desviación estándar del error
sigma[j] ~ dunif(0, 100)
tau[j] <- 1 / pow(sigma[j], 2)
}
# --- 3. Hiperpriors ---
mu_beta ~ dnorm(1, 0.1)     # Centrado en 1 (beta de mercado)
tau_beta ~ dgamma(0.1, 0.1) # Prior débilmente informativo
mu_alpha ~ dnorm(0, 0.1)    # Centrado en 0 (sin retorno anormal)
tau_alpha ~ dgamma(0.1, 0.1)
}
"
# Configuración MCMC
params_to_monitor <- c("alpha", "beta", "mu_alpha", "mu_beta", "sigma")
n_chains <- 3
n_adapt <- 1000
n_burnin <- 2000
n_iter <- 5000
cat("Configuración MCMC:")
cat("\n- Cadenas:", n_chains)
cat("\n- Adaptación:", n_adapt)
cat("\n- Burn-in:", n_burnin)
cat("\n- Iteraciones de muestreo:", n_iter)
# Crear y ajustar modelo JAGS
jags_model <- jags.model(textConnection(model_string),
data = jags_data,
n.chains = n_chains,
n.adapt = n_adapt)
# Burn-in
update(jags_model, n.iter = n_burnin)
# Muestrear distribuciones posteriores
posterior_samples <- coda.samples(jags_model,
variable.names = params_to_monitor,
n.iter = n_iter)
cat("¡Modelo jerárquico ajustado exitosamente!")
# Extraer estadísticas resumen
summary_stats <- summary(posterior_samples)
stats <- as.data.frame(summary_stats$statistics)
quants <- as.data.frame(summary_stats$quantiles)
# Crear mapeo correcto de índices a sectores
index_map <- data.frame(Index = 1:length(sector_names), Sector = sector_names)
# Aplicar nombres de sectores a los parámetros
for(i in 1:nrow(index_map)) {
rownames(stats) <- gsub(paste0("\\[", i, "\\]"),
paste0(" [", index_map$Sector[i], "]"),
rownames(stats))
rownames(quants) <- gsub(paste0("\\[", i, "\\]"),
paste0(" [", index_map$Sector[i], "]"),
rownames(quants))
}
# Resumen con nombres corregidos
results_table <- cbind(stats, quants) %>%
round(4)
print("Tabla de resultados creada exitosamente")
# Diagnóstico de Gelman-Rubin
gelman_diag <- gelman.diag(posterior_samples)
cat("=== DIAGNÓSTICO DE CONVERGENCIA ===")
cat("\nEstadístico de Gelman-Rubin (Rhat):")
print(gelman_diag)
cat("\nInterpretación:")
cat("\n- Rhat cercano a 1.0 indica convergencia adecuada")
cat("\n- Todos los valores deben estar por debajo de 1.1")
# Verificar convergencia
max_rhat <- max(gelman_diag$psrf[, "Upper C.I."])
if(max_rhat < 1.1) {
cat("\n✓ CONVERGENCIA EXITOSA: Todos los Rhat < 1.1")
} else {
cat("\n⚠ ADVERTENCIA: Algunos Rhat ≥ 1.1 - Considerar más iteraciones")
}
# Gráficos de traza para parámetros Beta
plot(posterior_samples[, grep("beta", varnames(posterior_samples))],
main = "Gráficos de Traza para Parámetros Beta")
# Obtener medias posteriores para predicciones
alpha_mean <- stats[grep("alpha \\[", rownames(stats)), "Mean"]
beta_mean <- stats[grep("beta \\[", rownames(stats)), "Mean"]
# Calcular predicciones y residuos
returns_long <- returns_long %>%
group_by(Sector_Index) %>%
mutate(
Predicted_Return = alpha_mean[Sector_Index] + beta_mean[Sector_Index] * SPY,
Residual = Sector_Return - Predicted_Return
) %>%
ungroup()
# Gráfico de residuos vs valores ajustados
residual_plot <- ggplot(returns_long, aes(x = Predicted_Return, y = Residual)) +
geom_point(alpha = 0.3, size = 0.8, color = "steelblue") +
geom_hline(yintercept = 0, color = "red", linetype = "dashed", linewidth = 1) +
facet_wrap(~ Sector_Label) +
labs(
title = "Análisis de Residuos por Sector",
subtitle = "Verificación de supuestos del modelo",
x = "Retorno Predicho (Valores Ajustados)",
y = "Residuos"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
strip.text = element_text(size = 11, face = "bold")
)
print(residual_plot)
# Gráfico Q-Q para normalidad
qq_plot <- ggplot(returns_long, aes(sample = Residual)) +
stat_qq(alpha = 0.2, size = 0.8, color = "steelblue") +
stat_qq_line(color = "red", linewidth = 1) +
facet_wrap(~ Sector_Label) +
labs(
title = "Gráficos Q-Q de Residuos por Sector",
subtitle = "Verificación de normalidad",
x = "Cuantiles Teóricos (Normal)",
y = "Cuantiles de la Muestra"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
strip.text = element_text(size = 11, face = "bold")
)
print(qq_plot)
# Extraer resultados de Beta
beta_results <- results_table[grep("beta \\[", rownames(results_table)),
c("Mean", "SD", "2.5%", "97.5%")]
# Agregar interpretación de riesgo
beta_results$Sector <- gsub(".*\\[(.+)\\].*", "\\1", rownames(beta_results))
beta_results$`Tipo de Riesgo` <- ifelse(beta_results$`97.5%` < 1, "Defensivo",
ifelse(beta_results$`2.5%` > 1, "Agresivo", "Neutral"))
# Ordenar por Beta medio
beta_results <- beta_results[order(beta_results$Mean, decreasing = TRUE), ]
# Crear tabla bonita
beta_table <- beta_results %>%
select(Sector, Mean, `2.5%`, `97.5%`, `Tipo de Riesgo`) %>%
mutate(
`IC 95%` = paste0("[", round(`2.5%`, 3), ", ", round(`97.5%`, 3), "]"),
`Beta Medio` = round(Mean, 3)
) %>%
select(Sector, `Beta Medio`, `IC 95%`, `Tipo de Riesgo`)
kable(beta_table,
caption = "Estimaciones de Beta por Sector (Modelo Jerárquico)",
format = "html",
table.attr = "class='table table-striped table-hover'")
# Extraer resultados de Alfa
alpha_results <- results_table[grep("alpha \\[", rownames(results_table)),
c("Mean", "SD", "2.5%", "97.5%")]
alpha_results$Sector <- gsub(".*\\[(.+)\\].*", "\\1", rownames(alpha_results))
# Verificar significancia estadística
alpha_results$`Significativo` <- ifelse(
alpha_results$`2.5%` > 0, "Positivo",
ifelse(alpha_results$`97.5%` < 0, "Negativo", "No significativo")
)
alpha_table <- alpha_results %>%
mutate(
`IC 95%` = paste0("[", round(`2.5%`, 6), ", ", round(`97.5%`, 6), "]"),
`Alfa Medio` = round(Mean, 6)
) %>%
select(Sector, `Alfa Medio`, `IC 95%`, Significativo)
kable(alpha_table,
caption = "Estimaciones de Alfa por Sector (Rendimiento Anormal)",
format = "html",
table.attr = "class='table table-striped table-hover'")
# Crear gráfico de intervalos de credibilidad para Beta
beta_plot_data <- beta_results %>%
mutate(
Sector_Label = factor(sector_labels[Sector],
levels = rev(c("Energía", "Finanzas", "Tecnología", "Consumo Básico")))
)
beta_plot <- ggplot(beta_plot_data, aes(x = Sector_Label, y = Mean)) +
geom_point(size = 4, color = "steelblue") +
geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`),
width = 0.2, size = 1, color = "steelblue") +
geom_hline(yintercept = 1, linetype = "dashed", color = "red", size = 1) +
coord_flip() +
labs(
title = "Estimaciones de Beta por Sector",
subtitle = "Intervalos de Credibilidad del 95% | Línea roja: β = 1 (riesgo de mercado)",
x = "Sector",
y = "Beta (Riesgo Sistémico)",
caption = "Modelo: Regresión Jerárquica Bayesiana"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12),
axis.title = element_text(size = 11),
axis.text = element_text(size = 10)
) +
annotate("text", x = 4.3, y = 1.02, label = "β = 1", color = "red", size = 3)
print(beta_plot)
# Modelo sin agrupamiento jerárquico
no_pooling_model_string <- "
model {
for (i in 1:N) {
R_sector[i] ~ dnorm(mu[i], tau[sector_idx[i]])
mu[i] <- alpha[sector_idx[i]] + beta[sector_idx[i]] * R_market[i]
}
for (j in 1:J) {
# Priors independientes (no jerárquicos)
beta[j] ~ dnorm(1, 0.1)
alpha[j] ~ dnorm(0, 0.1)
sigma[j] ~ dunif(0, 100)
tau[j] <- 1 / pow(sigma[j], 2)
}
}
"
# Ajustar modelo no-pooling
no_pooling_model <- jags.model(textConnection(no_pooling_model_string),
data = jags_data,
n.chains = n_chains,
n.adapt = n_adapt)
update(no_pooling_model, n.iter = n_burnin)
no_pooling_samples <- coda.samples(no_pooling_model,
variable.names = c("alpha", "beta", "sigma"),
n.iter = n_iter)
# Procesar resultados no-pooling
no_pooling_summary <- summary(no_pooling_samples)
no_pooling_stats <- as.data.frame(no_pooling_summary$statistics)
no_pooling_quants <- as.data.frame(no_pooling_summary$quantiles)
# Aplicar nombres de sectores
for(i in 1:nrow(index_map)) {
rownames(no_pooling_stats) <- gsub(paste0("\\[", i, "\\]"),
paste0(" [", index_map$Sector[i], "]"),
rownames(no_pooling_stats))
rownames(no_pooling_quants) <- gsub(paste0("\\[", i, "\\]"),
paste0(" [", index_map$Sector[i], "]"),
rownames(no_pooling_quants))
}
# Comparar precisión de estimaciones Beta
hierarchical_betas <- beta_results[, c("Mean", "SD", "2.5%", "97.5%")]
no_pooling_betas <- cbind(
no_pooling_stats[grep("beta \\[", rownames(no_pooling_stats)), c("Mean", "SD")],
no_pooling_quants[grep("beta \\[", rownames(no_pooling_quants)), c("2.5%", "97.5%")]
)
# Tabla comparativa
comparison_table <- data.frame(
Sector = gsub(".*\\[(.+)\\].*", "\\1", rownames(hierarchical_betas)),
Jerarquico_Beta = hierarchical_betas[, "Mean"],
Jerarquico_CI_Width = hierarchical_betas[, "97.5%"] - hierarchical_betas[, "2.5%"],
NoPooling_Beta = no_pooling_betas[, "Mean"],
NoPooling_CI_Width = no_pooling_betas[, "97.5%"] - no_pooling_betas[, "2.5%"]
) %>%
mutate(
Mejora_Precision = (NoPooling_CI_Width - Jerarquico_CI_Width) / NoPooling_CI_Width * 100
)
# Mostrar tabla de comparación
comparison_display <- comparison_table %>%
mutate(
`Beta Jerárquico` = round(Jerarquico_Beta, 3),
`Beta No-Pooling` = round(NoPooling_Beta, 3),
`Mejora en Precisión (%)` = round(Mejora_Precision, 1)
) %>%
select(Sector, `Beta Jerárquico`, `Beta No-Pooling`, `Mejora en Precisión (%)`)
kable(comparison_display,
caption = "Comparación de Modelos: Jerárquico vs No-Pooling",
format = "html",
table.attr = "class='table table-striped table-hover'")
# Comparación DIC (si es posible)
tryCatch({
hierarchical_dic <- dic.samples(jags_model, n.iter = 1000)
no_pooling_dic <- dic.samples(no_pooling_model, n.iter = 1000)
dic_comparison <- data.frame(
Modelo = c("Jerárquico", "No-Pooling"),
DIC = c(hierarchical_dic[[1]], no_pooling_dic[[1]])
)
cat("=== COMPARACIÓN DIC ===")
print(dic_comparison)
cat("\n(DIC menor indica mejor ajuste)")
}, error = function(e) {
cat("DIC no disponible en esta configuración")
})
# Información de la sesión para reproducibilidad
sessionInfo()
